{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec from scratch.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlF7QMw4_53M",
        "colab_type": "text"
      },
      "source": [
        "Word Embeddings are dense vector representations of words in low dimensional vector space. Word2Vec is the most popular word embedding model. The use of Word2Vec is to group words that semantically similar in vector space. It computes similarities mathematically.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUwMTg38_92r",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "There are two variants :\n",
        "1. CBOW (Continuous Bag of Words) : It tries to predict a word on based of its neighbours.\n",
        "2. SkipGram : It tries to predict the neighbours of a given word.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQJYsBptAERW",
        "colab_type": "text"
      },
      "source": [
        "1. Build a 3 layer neural network.\n",
        "2. The objective of network is to predict the neighbouring word given a word.\n",
        "3. Remove the last layer and keep the input and hidden layer.\n",
        "4. Now, input a word from within the vocabulary. The output given at the hidden layer is the ‘word embedding’ of the input word.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxUP9xbe2KgP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvd1IXK22pFf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_raw = 'He is the king . The king is royal . She is the royal queen'\n",
        "corpus_raw = corpus_raw.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZdH-sUI23Nr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = []\n",
        "for word in corpus_raw.split():\n",
        "    if word != '.': \n",
        "        words.append(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQGSWVpL3C54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words=set(words)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab0VTMFpII1s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1a5ae201-8205-46d9-9162-b8698e46149a"
      },
      "source": [
        "words"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'he', 'is', 'king', 'queen', 'royal', 'she', 'the'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQt_M02u3ICt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2int = {}\n",
        "int2word = {}\n",
        "vocab_size = len(words)\n",
        "\n",
        "for i,word in enumerate(words):\n",
        "    word2int[word] = i\n",
        "    int2word[i] = word"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa4A2qzY3fw5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "d8144760-fe60-449d-9242-e7802500b99e"
      },
      "source": [
        "print(word2int[\"queen\"])\n",
        "print(int2word[6])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "king\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWqWj8593vLB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_sentences = corpus_raw.split('.')\n",
        "sentences = []\n",
        "for sentence in raw_sentences:\n",
        "    sentences.append(sentence.split())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3C2R9Rc38zi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "9cfec63f-9fbc-4ac0-ce79-ff89f26b3055"
      },
      "source": [
        "print(sentences)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['he', 'is', 'the', 'king'], ['the', 'king', 'is', 'royal'], ['she', 'is', 'the', 'royal', 'queen']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi0F8kA33-BO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = []\n",
        "WINDOW_SIZE = 2\n",
        "\n",
        "def to_one_hot(data_point_index, vocab_size):\n",
        "    temp = np.zeros(vocab_size)\n",
        "    temp[data_point_index] = 1\n",
        "    return temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LF4wmUsv5Ctp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for sentence in sentences:\n",
        "    for word_index, word in enumerate(sentence):\n",
        "        for nb_word in sentence[max(word_index - WINDOW_SIZE, 0) : min(word_index + WINDOW_SIZE, len(sentence)) + 1] : \n",
        "            if nb_word != word:\n",
        "                data.append([word, nb_word])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbIGs-d7IW3b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "outputId": "1abb35a8-a64c-4145-ac32-161008e37c93"
      },
      "source": [
        "data"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['he', 'is'],\n",
              " ['he', 'the'],\n",
              " ['is', 'he'],\n",
              " ['is', 'the'],\n",
              " ['is', 'king'],\n",
              " ['the', 'he'],\n",
              " ['the', 'is'],\n",
              " ['the', 'king'],\n",
              " ['king', 'is'],\n",
              " ['king', 'the'],\n",
              " ['the', 'king'],\n",
              " ['the', 'is'],\n",
              " ['king', 'the'],\n",
              " ['king', 'is'],\n",
              " ['king', 'royal'],\n",
              " ['is', 'the'],\n",
              " ['is', 'king'],\n",
              " ['is', 'royal'],\n",
              " ['royal', 'king'],\n",
              " ['royal', 'is'],\n",
              " ['she', 'is'],\n",
              " ['she', 'the'],\n",
              " ['is', 'she'],\n",
              " ['is', 'the'],\n",
              " ['is', 'royal'],\n",
              " ['the', 'she'],\n",
              " ['the', 'is'],\n",
              " ['the', 'royal'],\n",
              " ['the', 'queen'],\n",
              " ['royal', 'is'],\n",
              " ['royal', 'the'],\n",
              " ['royal', 'queen'],\n",
              " ['queen', 'the'],\n",
              " ['queen', 'royal']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvDFNf-45vip",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = [] \n",
        "y_train = [] \n",
        "for data_word in data:\n",
        "    x_train.append(to_one_hot(word2int[ data_word[0] ], vocab_size))\n",
        "    y_train.append(to_one_hot(word2int[ data_word[1] ], vocab_size))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV4mphJR67_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.asarray(x_train)\n",
        "y_train = np.asarray(y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhHO3uzN7V8d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder(tf.float32, shape=(None, vocab_size))\n",
        "y_label = tf.placeholder(tf.float32, shape=(None, vocab_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G1t6cJv7l9K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "outputId": "23f2a28f-09c7-4d55-a624-7616c138d468"
      },
      "source": [
        "EMBEDDING_DIM = 5 \n",
        "W1 = tf.Variable(tf.random_normal([vocab_size, EMBEDDING_DIM]))\n",
        "b1 = tf.Variable(tf.random_normal([EMBEDDING_DIM]))\n",
        "hidden_representation = tf.add(tf.matmul(x,W1), b1)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5B1xs65-vAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, vocab_size]))\n",
        "b2 = tf.Variable(tf.random_normal([vocab_size]))\n",
        "prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_representation, W2), b2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QVkGuWyk8TwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init) \n",
        "\n",
        "# define the loss function:\n",
        "cross_entropy_loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), reduction_indices=[1]))\n",
        "# define the training step:\n",
        "train_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy_loss)\n",
        "n_iters = 10000\n",
        "# train for n_iter iterations\n",
        "for _ in range(n_iters):\n",
        "    sess.run(train_step, feed_dict={x: x_train, y_label: y_train})\n",
        "    print('loss is : ', sess.run(cross_entropy_loss, feed_dict={x: x_train, y_label: y_train}))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qyLByhs-VOg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "bd7e5696-c657-4cc7-b8be-6db93327bae4"
      },
      "source": [
        "print(sess.run(W1))\n",
        "print(sess.run(b1))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.2999856   1.3043436   1.1777382   1.6747016  -1.6034336 ]\n",
            " [-0.6418186  -1.6659697   0.6622133  -1.0588969  -1.478851  ]\n",
            " [ 0.5652176   0.76805556 -0.64750046 -0.09762229 -0.31200808]\n",
            " [ 0.13241744  0.16272512  2.3293061   0.582963    2.2461472 ]\n",
            " [ 0.11834886  1.5018452  -0.18658994 -0.33290207 -1.1634549 ]\n",
            " [-1.1003639  -2.7193942   0.19062264  1.9049916   1.1136706 ]\n",
            " [-0.36808482 -0.16243415 -0.68501765 -1.7686338   0.6701767 ]]\n",
            "[-1.5962734  1.3971279 -1.0591146 -1.8266429 -1.8087096]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIAGeaP3_IZj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vectors = sess.run(W1 + b1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTmue1QqHp0C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "8415d5c6-83cd-4b35-c9d2-f3a227f05c48"
      },
      "source": [
        "vectors"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.29628778,  2.7014713 ,  0.11862361, -0.1519413 , -3.4121432 ],\n",
              "       [-2.238092  , -0.26884186, -0.39690125, -2.8855398 , -3.2875605 ],\n",
              "       [-1.0310558 ,  2.1651835 , -1.706615  , -1.9242651 , -2.1207178 ],\n",
              "       [-1.463856  ,  1.559853  ,  1.2701916 , -1.2436799 ,  0.43743753],\n",
              "       [-1.4779246 ,  2.898973  , -1.2457045 , -2.159545  , -2.9721646 ],\n",
              "       [-2.6966372 , -1.3222663 , -0.86849195,  0.07834876, -0.69503903],\n",
              "       [-1.9643582 ,  1.2346938 , -1.7441323 , -3.5952768 , -1.1385329 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gxsjm8Pp_O6C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c5e9bfc2-2e95-4704-dc42-a82cf133ddb5"
      },
      "source": [
        "print(vectors[ word2int['queen'] ])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-2.238092   -0.26884186 -0.39690125 -2.8855398  -3.2875605 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRSXTLQe_jYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def euclidean_dist(vec1, vec2):\n",
        "    return np.sqrt(np.sum((vec1-vec2)**2))\n",
        "\n",
        "def find_closest(word_index, vectors):\n",
        "    min_dist = 10000 # to act like positive infinity\n",
        "    min_index = -1\n",
        "    query_vector = vectors[word_index]\n",
        "    for index, vector in enumerate(vectors):\n",
        "        if euclidean_dist(vector, query_vector) < min_dist and not np.array_equal(vector, query_vector):\n",
        "            min_dist = euclidean_dist(vector, query_vector)\n",
        "            min_index = index\n",
        "    return min_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVSeTy3M_oxG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "232ff38a-bfa5-4aa4-aeec-0a540d0a28d7"
      },
      "source": [
        "print(int2word[find_closest(word2int['queen'], vectors)])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "king\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}